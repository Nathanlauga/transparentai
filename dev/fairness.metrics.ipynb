{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transparentai.datasets import load_adult, load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transparentai.models import classification\n",
    "\n",
    "import transparentai.fairness as fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_adult()\n",
    "X, Y = data.drop(columns='income'), data['income']\n",
    "X = X.select_dtypes('number')\n",
    "Y = Y.replace({'>50K':1, '<=50K':0})\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = Y_train\n",
    "y_true_valid = Y_valid\n",
    "y_pred = clf.predict_proba(X_train)\n",
    "y_pred_valid = clf.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TPR': 0.524986849026828,\n",
       " 'FPR': 0.09775901266645015,\n",
       " 'confusion_matrix': array([[11112,  1204],\n",
       "        [ 1806,  1996]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = ['TPR','FPR', 'confusion_matrix']\n",
    "classification.compute_metrics(y_true_valid, y_pred_valid, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_group = {\n",
    "    'gender':['Male'],                # privileged group is man for gender attribute\n",
    "    'age': lambda x: x > 30 & x < 55,  # privileged group aged between 30 and 55 years old\n",
    "    'workclass': ['Private'],\n",
    "    'marital-status': lambda x: 'Married' in x,\n",
    "    'race':['White']    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21283</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25436</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  age  workclass  marital-status  race\n",
       "21283       0    0          1               1     1\n",
       "1815        0    1          1               0     1\n",
       "25436       1    1          0               0     0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privileged_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transparentai.fairness import metrics\n",
    "# metrics.statistical_parity_difference\n",
    "# metrics.equal_opportunity_difference\n",
    "# metrics.average_odds_difference\n",
    "# metrics.disparate_impact\n",
    "# metrics.theil_index\n",
    "\n",
    "# from transparentai.fairness import model_bias\n",
    "\n",
    "# model_bias(y_true, y_pred, social_attr, returns_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'statistical_parity_difference': -0.37232384428532844, 'disparate_impact': 0.14508294869705107, 'equal_opportunity_difference': 0.0012024767358392863, 'average_odds_difference': 0.00035237607077305696, 'theil_index': 0.0010234507425749904}\n",
      "{'statistical_parity_difference': -0.17332207645194392, 'disparate_impact': 0.40534380745537735, 'equal_opportunity_difference': 0.1021395855623608, 'average_odds_difference': 0.0320817599168834, 'theil_index': 0.14563763594900897}\n"
     ]
    }
   ],
   "source": [
    "from transparentai.models import evaluation \n",
    "\n",
    "def preprocess_y(y, pos_label):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    y = np.array(y)\n",
    "    \n",
    "    if len(y.shape) > 1:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    else:\n",
    "        y = np.round(y, 0)\n",
    "    \n",
    "    return (y == pos_label).astype(int)\n",
    "\n",
    "\n",
    "def base_rate(y, prot_attr, pos_label=1, privileged=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    prot_attr = np.array(prot_attr)\n",
    "    y = preprocess_y(y, pos_label)\n",
    "    \n",
    "    priv_cond = prot_attr == int(privileged)\n",
    "    n_priv    = np.sum(priv_cond)\n",
    "    n_pos     = np.sum(y[priv_cond] == 1)\n",
    "    \n",
    "    if n_priv > 0:\n",
    "        return n_pos / n_priv\n",
    "    return 1.\n",
    "\n",
    "\n",
    "def model_metrics_priv(metrics_fun, *args, privileged=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    y_true, y_pred = args[0], args[1]\n",
    "    prot_attr, pos_label = args[2], args[3]\n",
    "    \n",
    "    y_true = preprocess_y(y_true, pos_label)\n",
    "    y_pred = preprocess_y(y_pred, pos_label)\n",
    "    \n",
    "    y_true = y_true[prot_attr == int(privileged)]\n",
    "    y_pred = y_pred[prot_attr == int(privileged)]\n",
    "    \n",
    "    return metrics_fun(y_true, y_pred)\n",
    "\n",
    "\n",
    "def tpr_privileged(*args, privileged=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    metrics_fun = evaluation.classification.true_positive_rate\n",
    "    return model_metrics_priv(metrics_fun, *args, privileged=privileged)\n",
    "    \n",
    "def fpr_privileged(*args, privileged=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    metrics_fun = evaluation.classification.false_positive_rate\n",
    "    return model_metrics_priv(metrics_fun, *args, privileged=privileged)\n",
    "    \n",
    "    \n",
    "    \n",
    "def difference(metric_fun, *args):\n",
    "    \"\"\"Computes difference of the metric for \n",
    "    unprivileged and privileged groups.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metric_fun: function\n",
    "        metric function that returns a number\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float:\n",
    "        Difference of a metric for \n",
    "        unprivileged and privileged groups.\n",
    "    \"\"\"\n",
    "    return (metric_fun(*args, privileged=False)\n",
    "            - metric_fun(*args, privileged=True))\n",
    "    \n",
    "    \n",
    "def ratio(metric_fun, *args):\n",
    "    \"\"\"Computes ratio of the metric for \n",
    "    unprivileged and privileged groups.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metric_fun: function\n",
    "        metric function that returns a number\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float:\n",
    "        Ratio of a metric for \n",
    "        unprivileged and privileged groups.\n",
    "    \"\"\"\n",
    "    return (metric_fun(*args, privileged=False)\n",
    "            / metric_fun(*args, privileged=True))\n",
    "\n",
    "    \n",
    "def statistical_parity_difference(y, prot_attr, pos_label=1):\n",
    "    \"\"\"Computed as the difference of the rate of \n",
    "    favorable outcomes received by the unprivileged group \n",
    "    to the privileged group.\n",
    "\n",
    "    The ideal value of this metric is 0 A value < 0 implies \n",
    "    higher benefit for the privileged group and a value > 0 \n",
    "    implies a higher benefit for the unprivileged group.\n",
    "\n",
    "    Fairness for this metric is between -0.1 and 0.1\n",
    "\n",
    "    Pr(Y^=pos_label|D=unprivileged)−Pr(Y^=pos_label|D=privileged)\n",
    "    \n",
    "    src : \n",
    "    \n",
    "    - https://fairware.cs.umass.edu/papers/Verma.pdf\n",
    "    - https://aif360.readthedocs.io/en/latest/modules/generated/aif360.sklearn.metrics.statistical_parity_difference.html?highlight=Statistical%20Parity%20Difference#aif360.sklearn.metrics.statistical_parity_difference\n",
    "    \n",
    "    \"\"\"\n",
    "    # prot_attr same len as y_pred\n",
    "    \n",
    "    return difference(base_rate, y, prot_attr, pos_label)\n",
    "\n",
    "def disparate_impact(y, prot_attr, pos_label=1):\n",
    "    \"\"\"Computed as the ratio of rate of favorable outcome for \n",
    "    the unprivileged group to that of the privileged group.\n",
    "\n",
    "    The ideal value of this metric is 1.0 A value < 1 implies \n",
    "    higher benefit for the privileged group and a value > 1 \n",
    "    implies a higher benefit for the unprivileged group.\n",
    "\n",
    "    Fairness for this metric is between 0.8 and 1.2\n",
    "    \n",
    "    .. math::\n",
    "           \\frac{Pr(\\hat{Y} = 1 | D = \\text{unprivileged})}\n",
    "           {Pr(\\hat{Y} = 1 | D = \\text{privileged})}\n",
    "    \n",
    "    src : \n",
    "    \n",
    "    - https://aif360.readthedocs.io/en/latest/modules/generated/aif360.sklearn.metrics.disparate_impact_ratio.html?highlight=Disparate%20Impact#aif360.sklearn.metrics.disparate_impact_ratio\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # prot_attr same len as y_pred\n",
    "    \n",
    "    return ratio(base_rate, y, prot_attr, pos_label)\n",
    "\n",
    "    \n",
    "def equal_opportunity_difference(y_true, y_pred, prot_attr, pos_label=1):\n",
    "    \"\"\"This metric is computed as the difference of \n",
    "    true positive rates between the unprivileged and \n",
    "    the privileged groups. The true positive rate is \n",
    "    the ratio of true positives to the total number \n",
    "    of actual positives for a given group.\n",
    "\n",
    "    The ideal value is 0. A value of < 0 implies higher \n",
    "    benefit for the privileged group and a value > 0 implies \n",
    "    higher benefit for the unprivileged group.\n",
    "\n",
    "    Fairness for this metric is between -0.1 and 0.1\n",
    "\n",
    "    TPRD=unprivileged − TPRD=privileged\n",
    "    \n",
    "    src : \n",
    "    \n",
    "    - https://aif360.readthedocs.io/en/latest/modules/generated/aif360.sklearn.metrics.equal_opportunity_difference.html?highlight=Equal%20Opportunity%20Difference\n",
    "        \n",
    "    \"\"\"\n",
    "    return difference(tpr_privileged, y_true, y_pred, prot_attr, pos_label)\n",
    "\n",
    "def average_odds_difference(y_true, y_pred, prot_attr, pos_label=1):\n",
    "    \"\"\"Computed as average difference of false positive rate \n",
    "    (false positives / negatives) and true positive rate \n",
    "    (true positives / positives) between unprivileged and \n",
    "    privileged groups.\n",
    "\n",
    "    The ideal value of this metric is 0. A value of < 0 implies\n",
    "    higher benefit for the privileged group and a value > 0\n",
    "    implies higher benefit for the unprivileged group.\n",
    "\n",
    "    Fairness for this metric is between -0.1 and 0.1\n",
    "    \n",
    "    1/2 [(FPRD=unprivileged−FPRD=privileged) + \n",
    "    (TPRD=unprivileged−TPRD=privileged))]\n",
    "    \n",
    "    src :\n",
    "    \n",
    "    - https://aif360.readthedocs.io/en/latest/modules/generated/aif360.sklearn.metrics.average_odds_difference.html?highlight=Average%20Odds%20Difference#aif360.sklearn.metrics.average_odds_difference\n",
    "    \n",
    "    \"\"\"\n",
    "    args = [y_true, y_pred, prot_attr, pos_label]\n",
    "    return (1/2) * (\n",
    "        difference(fpr_privileged, *args) + difference(tpr_privileged, *args)\n",
    "    )\n",
    "\n",
    "def theil_index(y_true, y_pred, prot_attr, pos_label=1):\n",
    "    \"\"\"Computed as the generalized entropy of benefit \n",
    "    for all individuals in the dataset, with alpha = 1. \n",
    "    It measures the inequality in benefit allocation for individuals.\n",
    "\n",
    "    A value of 0 implies perfect fairness.\n",
    "\n",
    "    Fairness is indicated by lower scores, higher scores are problematic\n",
    "\n",
    "    With bi=y^i−yi+1:\n",
    "    1/n ∑ bi/μ (ln(bi/μ))\n",
    "    \n",
    "    src :\n",
    "    \n",
    "    - https://aif360.readthedocs.io/en/latest/modules/generated/aif360.metrics.ClassificationMetric.html?highlight=Theil%20Index#aif360.metrics.ClassificationMetric.generalized_entropy_index\n",
    "    \n",
    "    \"\"\"\n",
    "    y_true = preprocess_y(y_true, pos_label)\n",
    "    y_pred = preprocess_y(y_pred, pos_label)\n",
    "    \n",
    "    b = y_pred - y_true + 1\n",
    "    \n",
    "    return np.mean(np.log((b / np.mean(b))**b) / np.mean(b))\n",
    "    \n",
    "FAIRNESS_METRICS = {\n",
    "    'statistical_parity_difference':statistical_parity_difference,\n",
    "    'disparate_impact':disparate_impact,\n",
    "    'equal_opportunity_difference':equal_opportunity_difference,\n",
    "    'average_odds_difference':average_odds_difference,\n",
    "    'theil_index':theil_index\n",
    "}\n",
    "\n",
    "def preprocess_metrics(input_metrics, metrics_dict):\n",
    "    \"\"\"Preprocess the inputed metrics so that it maps\n",
    "    with the appropriate function in METRICS global variable.\n",
    "\n",
    "    input_metrics can have str or function. If it's a string\n",
    "    then it has to be a key from METRICS global variable dict\n",
    "\n",
    "    Returns a dictionnary with metric's name as key and \n",
    "    metric function as value\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_metrics: list\n",
    "        List of metrics to compute\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict:\n",
    "        Dictionnary with metric's name as key and \n",
    "        metric function as value\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    TypeError:\n",
    "        input_metrics must be a list\n",
    "    \"\"\"\n",
    "    if type(input_metrics) != list:\n",
    "        raise TypeError('input_metrics must be a list')\n",
    "\n",
    "    fn_dict = {}\n",
    "    cnt_custom = 1\n",
    "\n",
    "    for fn in input_metrics:\n",
    "        if type(fn) == str:\n",
    "            if fn in metrics_dict:\n",
    "                fn_dict[fn] = metrics_dict[fn]\n",
    "            else:\n",
    "                warnings.warn('%s function not found' % fn)\n",
    "        else:\n",
    "            fn_dict['custom_'+str(cnt_custom)] = fn\n",
    "            cnt_custom += 1\n",
    "\n",
    "    if len(fn_dict.keys()) == 0:\n",
    "        raise ValueError('No valid metrics found')\n",
    "\n",
    "    return fn_dict\n",
    "\n",
    "    \n",
    "def compute_metrics(y_true, y_pred, metrics, prot_attr, pos_label=1):\n",
    "    \"\"\"Computes the inputed metrics.\n",
    "\n",
    "    metrics can have str or function. If it's a string\n",
    "    then it has to be a key from FAIRNESS_METRICS global variable dict.\n",
    "\n",
    "    Returns a dictionnary with metric's name as key and \n",
    "    metric function's result as value\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: array like\n",
    "        True labels\n",
    "    y_pred: array like\n",
    "        Predicted labels\n",
    "    metrics: list\n",
    "        List of metrics to compute\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict:\n",
    "        Dictionnary with metric's name as key and \n",
    "        metric function's result as value\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    TypeError:\n",
    "        metrics must be a list\n",
    "    \"\"\"\n",
    "    if type(metrics) != list:\n",
    "        raise TypeError('metrics must be a list')\n",
    "\n",
    "    if type(y_true) == list:\n",
    "        y_true = np.array(y_true)\n",
    "    if type(y_pred) == list:\n",
    "        y_pred = np.array(y_pred)\n",
    "        \n",
    "    metrics = preprocess_metrics(input_metrics=metrics,\n",
    "                                 metrics_dict=FAIRNESS_METRICS)\n",
    "    res = {}\n",
    "    args = []\n",
    "    for name, fn in metrics.items():\n",
    "        need_both = 'y_true' in fn.__code__.co_varnames\n",
    "\n",
    "        if need_both:\n",
    "            res[name] = fn(y_true, y_pred, prot_attr, pos_label)\n",
    "        else:\n",
    "            res[name] = fn(y_pred, prot_attr, pos_label)\n",
    "\n",
    "    return res\n",
    "\n",
    "df = data.loc[X_valid.index,:]\n",
    "privileged_df = fairness.create_privilieged_df(df, privileged_group)\n",
    "prot_attr_valid = privileged_df['marital-status']\n",
    "\n",
    "df = data.loc[X_train.index,:]\n",
    "privileged_df = fairness.create_privilieged_df(df, privileged_group)\n",
    "prot_attr = privileged_df['marital-status']\n",
    "\n",
    "pos_label = 1\n",
    "\n",
    "metrics = [\n",
    "    'statistical_parity_difference',\n",
    "    'disparate_impact',\n",
    "    'equal_opportunity_difference',\n",
    "    'average_odds_difference',\n",
    "    'theil_index',\n",
    "]\n",
    "\n",
    "res_train = compute_metrics(y_true, \n",
    "                          y_pred, \n",
    "                          metrics, \n",
    "                          prot_attr, \n",
    "                          pos_label)\n",
    "\n",
    "res = compute_metrics(y_true_valid, \n",
    "                      y_pred_valid, \n",
    "                      metrics, \n",
    "                      prot_attr_valid, \n",
    "                      pos_label)\n",
    "print(res_train)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
