{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "from transparentai.datasets import load_adult, load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transparentai.models import classification\n",
    "\n",
    "import transparentai.fairness as fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install BlackBoxAuditing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_adult()\n",
    "X, Y = data.drop(columns='income'), data['income']\n",
    "X = X.select_dtypes('number')\n",
    "Y = Y.replace({'>50K':1, '<=50K':0})\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "clf = RandomForestClassifier().fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = Y_train\n",
    "y_true_valid = Y_valid\n",
    "y_pred = clf.predict_proba(X_train)\n",
    "y_pred_valid = clf.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_group = {\n",
    "    'gender':['Male'],              \n",
    "#     'marital-status': lambda x: 'Married' in x,\n",
    "    'race':['White']\n",
    "}\n",
    "\n",
    "df_valid = data.loc[X_valid.index,:]\n",
    "df_train = data.loc[X_train.index,:]\n",
    "\n",
    "res_train1 = fairness.compute_fairness_metrics(y_true, \n",
    "                                     y_pred, \n",
    "                                     df_train,\n",
    "                                     privileged_group)\n",
    "\n",
    "res_valid1 = fairness.compute_fairness_metrics(y_true_valid, \n",
    "                                     y_pred_valid, \n",
    "                                     df_valid,\n",
    "                                     privileged_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': {'statistical_parity_difference': -0.10176688863821445,\n",
       "  'disparate_impact': 0.5629035343040948,\n",
       "  'equal_opportunity_difference': -0.05801792869649808,\n",
       "  'average_odds_difference': -0.0362636081490145,\n",
       "  'theil_index': 0.14631697193948695},\n",
       " 'race': {'statistical_parity_difference': -0.054154865761862986,\n",
       "  'disparate_impact': 0.7387421874119033,\n",
       "  'equal_opportunity_difference': -0.007496974897146402,\n",
       "  'average_odds_difference': -0.006428405988372209,\n",
       "  'theil_index': 0.14631697193948695}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_valid1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms import preprocessing\n",
    "\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.algorithms.preprocessing import LFR, Reweighing\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing, EqOddsPostprocessing, RejectOptionClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def DataFrame_to_StandardDataset(df, target, privileged_group, favorable_label):\n",
    "    \"\"\"Converts a pandas.DataFrame into a \n",
    "    aif360.datasets.StandardDataset to use bias \n",
    "    processing algorithms.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        DataFrame to convert\n",
    "    target: str\n",
    "        Column's name of the target\n",
    "    privileged_group: dict\n",
    "        Dictionnary with protected attribute as key (e.g. age or gender)\n",
    "        and a list of favorable value (like ['Male']) or a function\n",
    "        returning a boolean corresponding to a privileged group\n",
    "    favorable_label: list or value\n",
    "        The label of the favorable class. Needs to be in\n",
    "        the df[target] column's unique value\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    aif360.datasets.StandardDataset:\n",
    "        DataFrame converted\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError:\n",
    "        df must be a pandas.DataFrame\n",
    "    ValueError:\n",
    "        target must be in df columns\n",
    "    ValueError:\n",
    "        At least one value of the favorable_label list needs to be in df[target]\n",
    "    ValueError:\n",
    "        favorable_label must be in df[target]\n",
    "    \"\"\"\n",
    "    if type(df) != pd.DataFrame:\n",
    "        raise TypeError('df must be a pandas.DataFrame')\n",
    "    if target not in df.columns:\n",
    "        raise ValueError('target must be in df columns')\n",
    "    if (type(favorable_label) == list) & (\n",
    "        not any([v in df[target].unique() for v in favorable_label])):\n",
    "        raise ValueError('At least one value of the favorable_label list needs to be in df[target]')\n",
    "    elif (type(favorable_label) != list):\n",
    "        if (favorable_label not in df[target].unique()):\n",
    "            raise ValueError('favorable_label must be in df[target]')\n",
    "    \n",
    "    df = df.copy()\n",
    "    privileged_classes = [v for (k,v) in privileged_group.items()]\n",
    "    \n",
    "    if type(favorable_label) == list:\n",
    "        df[target] = (df[target].isin(favorable_label)).astype(int)\n",
    "    else:\n",
    "        df[target] = (df[target] == favorable_label).astype(int)\n",
    "    \n",
    "    num_feats = df.select_dtypes('number').columns.tolist()\n",
    "    \n",
    "    protected_attribute_names = list(privileged_group.keys())\n",
    "    privileged_classes = list()\n",
    "\n",
    "    # Use Label Encoder for categorical columns (including target column)\n",
    "    for attr, values in privileged_group.items():\n",
    "        if attr in num_feats:\n",
    "            privileged_classes.append(values)\n",
    "            continue\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[attr])\n",
    "\n",
    "        df[attr] = le.transform(df[attr])\n",
    "        if type(values) == type(lambda x:x):\n",
    "            fn = values\n",
    "            tmp = [i for (i,v) in enumerate(le.classes_) if fn(v)]\n",
    "            \n",
    "        else:\n",
    "            tmp = [np.where(le.classes_ == v)[0][0] for v in values]\n",
    "        privileged_classes.append(tmp)\n",
    "        \n",
    "        num_feats += [attr]\n",
    "    \n",
    "    categorical_features = [c for c in df.columns if c not in num_feats]\n",
    "    \n",
    "    return StandardDataset(df=df, \n",
    "                   label_name=target, \n",
    "                   favorable_classes=[1],\n",
    "                   categorical_features=categorical_features,\n",
    "                   protected_attribute_names=protected_attribute_names,\n",
    "                   privileged_classes=privileged_classes)\n",
    "    \n",
    "\n",
    "def get_priv_unpriv_grousp(dataset):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    unprivileged_groups = privileged_groups = list()\n",
    "    \n",
    "    for i, attr in enumerate(dataset.protected_attribute_names):\n",
    "        unprivileged_groups.append({attr: dataset.unprivileged_protected_attributes[i]})\n",
    "        privileged_groups.append({attr: dataset.privileged_protected_attributes[i]})\n",
    "    \n",
    "    return privileged_groups, unprivileged_groups\n",
    "\n",
    "\n",
    "from aif360.algorithms.preprocessing import LFR, Reweighing, DisparateImpactRemover\n",
    "preprocessing_algo = ['LFR','Reweighing','DisparateImpactRemover']\n",
    "    \n",
    "def mitigate_bias(df, target, privileged_group, favorable_label, model=None, algorithm=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset = DataFrame_to_StandardDataset(df, target, \n",
    "                                           privileged_group, \n",
    "                                           favorable_label)\n",
    "    \n",
    "    privileged_groups, unprivileged_groups = get_priv_unpriv_grousp(dataset)\n",
    "    \n",
    "    dataset_transf = dataset.copy()\n",
    "    \n",
    "    if algorithm == 'Reweighing':\n",
    "        obj = Reweighing(unprivileged_groups, privileged_groups)\n",
    "        dataset_transf = obj.fit_transform(dataset_transf)\n",
    "    \n",
    "    elif algorithm == 'DisparateImpactRemover':        \n",
    "        for attr in privileged_group:\n",
    "            obj = DisparateImpactRemover(sensitive_attribute=attr)\n",
    "            dataset_transf = obj.fit_transform(dataset_transf)\n",
    "    \n",
    "    elif algorithm == 'LFR':        \n",
    "        for unpriv_group, priv_group in zip(unprivileged_groups, privileged_groups):\n",
    "            obj = LFR([unpriv_group], [priv_group], k=1, verbose=0)\n",
    "            dataset_transf = obj.fit_transform(dataset_transf)\n",
    "        \n",
    "    X = dataset_transf.features\n",
    "    y = dataset_transf.labels.ravel()\n",
    "    \n",
    "    model.fit(X, y, sample_weight=dataset_transf.instance_weights)\n",
    "    \n",
    "    print('ok')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reweighing\n",
      "ok\n",
      "DisparateImpactRemover\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "privileged_group = {\n",
    "    'gender':['Male'], \n",
    "    'race':['White']\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(max_depth=10)\n",
    "models = list()\n",
    "for algo in preprocessing_algo:\n",
    "    if algo =='LFR':\n",
    "        continue\n",
    "        \n",
    "    print(algo)\n",
    "    tmp = mitigate_bias(data, 'income', privileged_group, '>50K',\n",
    "                        model=model, algorithm=algo)\n",
    "    models.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = Y_train\n",
    "y_true_valid = Y_valid\n",
    "\n",
    "fairness_scores_train = list()\n",
    "fairness_scores_valid = list()\n",
    "\n",
    "df_valid = data.loc[X_valid.index,:]\n",
    "df_train = data.loc[X_train.index,:]\n",
    "\n",
    "df_train = DataFrame_to_StandardDataset(df_train, 'income', \n",
    "                                           privileged_group, \n",
    "                                           '>50K')\n",
    "df_valid = DataFrame_to_StandardDataset(df_valid, 'income', \n",
    "                                           privileged_group, \n",
    "                                           '>50K')\n",
    "\n",
    "for model in models:\n",
    "    y_pred = model.predict_proba(df_train.features)\n",
    "    y_pred_valid = model.predict_proba(df_valid.features)\n",
    "    \n",
    "    tmp = fairness.compute_fairness_metrics(y_true, \n",
    "                                     y_pred, \n",
    "                                     df_train.convert_to_dataframe()[0],\n",
    "                                     privileged_group)\n",
    "    \n",
    "    fairness_scores_train.append(tmp)\n",
    "    \n",
    "    tmp = fairness.compute_fairness_metrics(y_true_valid, \n",
    "                                     y_pred_valid, \n",
    "                                     df_valid.convert_to_dataframe()[0],\n",
    "                                     privileged_group)\n",
    "    fairness_scores_valid.append(tmp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': {'statistical_parity_difference': -0.8313164649798312,\n",
       "  'disparate_impact': 0.1686835350201687,\n",
       "  'equal_opportunity_difference': -0.4512365250475586,\n",
       "  'average_odds_difference': -0.7016036081496096,\n",
       "  'theil_index': 0.12949214452620358},\n",
       " 'race': {'statistical_parity_difference': -0.8313164649798312,\n",
       "  'disparate_impact': 0.1686835350201687,\n",
       "  'equal_opportunity_difference': -0.4512365250475586,\n",
       "  'average_odds_difference': -0.7016036081496096,\n",
       "  'theil_index': 0.12949214452620358}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness_scores_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': {'statistical_parity_difference': -0.8313164649798312,\n",
       "  'disparate_impact': 0.1686835350201687,\n",
       "  'equal_opportunity_difference': -0.4512365250475586,\n",
       "  'average_odds_difference': -0.7016036081496096,\n",
       "  'theil_index': 0.12949214452620358},\n",
       " 'race': {'statistical_parity_difference': -0.8313164649798312,\n",
       "  'disparate_impact': 0.1686835350201687,\n",
       "  'equal_opportunity_difference': -0.4512365250475586,\n",
       "  'average_odds_difference': -0.7016036081496096,\n",
       "  'theil_index': 0.12949214452620358}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness_scores_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': {'statistical_parity_difference': -0.1943527482593205,\n",
       "  'disparate_impact': 0.36280897023389447,\n",
       "  'equal_opportunity_difference': 0.002533869555253143,\n",
       "  'average_odds_difference': 0.0010216595530061028,\n",
       "  'theil_index': 0.001035250447756525},\n",
       " 'race': {'statistical_parity_difference': -0.09475373448371352,\n",
       "  'disparate_impact': 0.6269521232190262,\n",
       "  'equal_opportunity_difference': 0.001269924973875347,\n",
       "  'average_odds_difference': 0.00039545300236208436,\n",
       "  'theil_index': 0.001035250447756525}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
